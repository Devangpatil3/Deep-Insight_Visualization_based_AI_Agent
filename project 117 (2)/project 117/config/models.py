"""Model configurations for different AI providers"""

TOGETHER_MODELS = {
    "Meta-Llama 3.1 405B": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "DeepSeek V3": "deepseek-ai/DeepSeek-V3",
    "Qwen 2.5 7B": "Qwen/Qwen2.5-7B-Instruct-Turbo",
    "Meta-Llama 3.3 70B": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
    "Mixtral 8x7B": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "Code Llama 34B": "codellama/CodeLlama-34b-Instruct-hf"
}

MODEL_DESCRIPTIONS = {
    "Meta-Llama 3.1 405B": "Most powerful model, best for complex analysis",
    "DeepSeek V3": "Excellent for coding and data analysis",
    "Qwen 2.5 7B": "Fast and efficient for simple tasks",
    "Meta-Llama 3.3 70B": "Balanced performance and speed",
    "Mixtral 8x7B": "Good for general tasks",
    "Code Llama 34B": "Specialized for code generation"
}